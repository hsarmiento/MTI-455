{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"colab":{"name":"Lab 2.2 PAUTA.ipynb","provenance":[],"collapsed_sections":[]},"hide_input":false,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"p_XcuC2rXQWb","pycharm":{}},"source":["# PAUTA Laboratorio 2.2: Clasificación\n","\n","Hernán Sarmiento, Andrés Abeliuk, Alison Fernandez, Cinthia Sánchez, Johnny Godoy, Gabriel Ramos, Cristian Llull y Matías Rojas\n","\n","Octubre 2021"]},{"cell_type":"markdown","metadata":{"id":"SMUzxXj7XQWi","pycharm":{}},"source":["# Instrucciones\n","\n","\n","1. Trabajen en equipos de dos personas. Salvo excepciones, no se corregirá entregas con menos de dos integrantes.\n","\n","2. Modifique este archivo `.ipynb` agregando sus respuestas donde corresponda. \n","\n","3. El formato de entrega para esta actividad es un archivo html. **Genere un archivo HTML** usando jupyter (ver tutorial 2) y súbalo a U-Cursos. Basta con que uno de los integrantes haga la entrega. Si ambos hacen una entrega en U-Cursos, se revisará cualquiera de éstas."]},{"cell_type":"markdown","metadata":{"id":"1Zo8shEyQ3um"},"source":["# Estructura del laboratorio\n","\n","Este laboratorio está conformado por preguntas teóricas de temas vistos en clases y preguntas prácticas (donde se requiere completar código) intercaladas con preguntas de interpretación de resultados y análisis. La parte práctica se divide en: \n","\n","1. Comparar clasificadores con ciertos *baselines* o clasificadores base.\n","2. Seleccionar hiperparámetros.\n","3. Trabajar con clases desbalanceadas."]},{"cell_type":"markdown","metadata":{"id":"Ypf5cpbRQ3un"},"source":["# Teoría"]},{"cell_type":"markdown","metadata":{"id":"un5w_agBQ3un"},"source":["#### 1. Explique cómo escoge un árbol de decisión el atributo raíz.\n","\n","**Respuesta:** Evaluando para todos los atributos el information gain de la partición del dataset que generan y encontrando el atributo que maximiza ese valor."]},{"cell_type":"markdown","metadata":{"id":"dbQc-0jJQ3un"},"source":["#### 2. Explique el problema de optimización que resuelve una SVM lineal.\n","\n","**Respuesta:** La SVM plantea un problema que maximiza el margen del hiperplano separador asegurando que todos los objetos queden bien clasificados i.e., los positivos por sobre del hiperplano y los negativos bajo este."]},{"cell_type":"markdown","metadata":{"id":"GKw1ZZVIQ3uo"},"source":["#### 3. ¿Qué es overfitting y underfitting en machine learning?\n","\n","**Respuesta:** (Al final de la clase 6 hay un tema \"Problemas prácticos en la clasificación\" donde se habla de cómo interpretar los errores y se habla de overfitting y underfitting.)"]},{"cell_type":"markdown","metadata":{"id":"LCJ9w1GfXQXL","pycharm":{}},"source":["# Parte 1: Comparar clasificadores"]},{"cell_type":"markdown","metadata":{"id":"XqPvhC1XXADR"},"source":["Una de las principales tareas en enfoques supervisados es evaluar diferentes clasificadores y encontrar el mejor rendimiento de alguno de ellos. Por ejemplo, si tenemos dos (o más) clasificadores y queremos compararlos entre sí, nos interesa responder: *¿Cuál de los clasificadores es el mejor?* \n","Para responder esta pregunta, no existe una única solución. \n","\n","Lo que haremos a continuación será ejecutar diferentes clasificadores y compararlos en base a las métricas de Precision, Recall y F1-score."]},{"cell_type":"markdown","metadata":{"id":"c9ohYCUFXADR"},"source":["## Pregunta 1.1  \n","\n","Para realizar la evaluación de distintos clasificadores, vamos a crear la función `run_classifier()`, la cual evalúa un clasificador `clf` recibido como parámetro, un dataset `X,y` (features y target) y un número de tests llamado `num_test`. Esta función almacena y retorna los valores de precision, recall y f1-score en la variable `metrics` además de los resultados de predicción.\n","\n","En base a lo anterior, incluya las sentencias que ajusten el modelo junto a su correspondiente predicción sobre los datos. **No use cross-validation ni tampoco el parámetro `random_state`.**\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:34.028494Z","start_time":"2020-09-28T01:11:34.018999Z"},"id":"TndzyqreXADS"},"source":["### COMPLETAR ESTE CÓDIGO\n","\n","## run_classifier recibe un clasificador y un dataset (X, y)\n","## y opcionalmente la cantidad de resultados que se quiere obtener del clasificador\n","\n","from sklearn.metrics import f1_score, recall_score, precision_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","def run_classifier(clf, X, y, num_tests=100):\n","    metrics = {'f1-score': [], 'precision': [], 'recall': []}\n","    \n","    for _ in range(num_tests):\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n","        ### INICIO COMPLETAR ACÁ \n","        \n","        #### TIP: en base a los set de entrenamiento, genere la variable 'predictions' \n","        #### que contiene las predicciones del modelo\n","        \n","       \n","        ## INICIO PAUTA\n","        \n","        clf.fit(X_train, y_train)\n","        predictions = clf.predict(X_test)\n","\n","        ## FIN PAUTA\n","        \n","        ### FIN COMPLETAR ACÁ\n","        \n","        metrics['y_pred'] = predictions\n","        metrics['f1-score'].append(f1_score(y_test, predictions)) \n","        metrics['recall'].append(recall_score(y_test, predictions))\n","        metrics['precision'].append(precision_score(y_test, predictions))\n","    return metrics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VjXFx9xIXADU"},"source":["Luego de completar el código anterior, ejecute el siguiente bloque para comparar distintos clasificadores. \n","Usaremos un **dataset de cáncer de mamas** para evaluar. La información del dataset se puede encontrar en el siguiente link: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"]},{"cell_type":"code","metadata":{"id":"-4VE-nVyufYp","executionInfo":{"status":"ok","timestamp":1634045932762,"user_tz":180,"elapsed":1337,"user":{"displayName":"Hernán Sarmiento","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjl_11ssgu01a2DUqEjYM2ty47SC6fJ-NdViROw=s64","userId":"00750421326633201373"}}},"source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.dummy import DummyClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB  # naive bayes\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC  # support vector machine classifier\n","\n","bc = load_breast_cancer()    # dataset cancer de mamas\n","X = bc.data\n","y = bc.target"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QMMXE5-vd59","executionInfo":{"status":"ok","timestamp":1634046188986,"user_tz":180,"elapsed":377,"user":{"displayName":"Hernán Sarmiento","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjl_11ssgu01a2DUqEjYM2ty47SC6fJ-NdViROw=s64","userId":"00750421326633201373"}},"outputId":"ea92cbc0-0f83-4de9-8895-713861026520"},"source":["bc.keys()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUUVPHaeviZf","executionInfo":{"status":"ok","timestamp":1634046340317,"user_tz":180,"elapsed":205,"user":{"displayName":"Hernán Sarmiento","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjl_11ssgu01a2DUqEjYM2ty47SC6fJ-NdViROw=s64","userId":"00750421326633201373"}},"outputId":"4cf9116d-623f-4b68-a631-f551da615dfe"},"source":["import pandas as pd \n","from sklearn.datasets import load_breast_cancer\n","\n","bc = load_breast_cancer()    # dataset cancer de mamas\n","X = bc.data\n","y = bc.target\n","\n","li_classes = [bc.target_names[1], bc.target_names[0]]\n","li_target = [1 if x==0 else 0 for x in list(bc.target)]\n","li_ftrs = list(bc.feature_names)\n","\n","print(\"There are 2 target classes:\")\n","print(\"li_classes\", li_classes)\n","\n","print(\"Target class distribution from a total of %d target values:\" % len(li_target))\n","print(pd.Series(li_target).value_counts())"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 2 target classes:\n","li_classes ['benign', 'malignant']\n","Target class distribution from a total of 569 target values:\n","0    357\n","1    212\n","dtype: int64\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCnrNd7kuiOU","executionInfo":{"status":"ok","timestamp":1634045935203,"user_tz":180,"elapsed":246,"user":{"displayName":"Hernán Sarmiento","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUjl_11ssgu01a2DUqEjYM2ty47SC6fJ-NdViROw=s64","userId":"00750421326633201373"}},"outputId":"3eccc933-c1d3-40ca-9f31-47708e021b24"},"source":["y"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n","       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n","       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n","       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n","       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n","       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n","       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n","       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:37.747387Z","start_time":"2020-09-28T01:11:34.031505Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"-P2TfM7_XADU","scrolled":false,"executionInfo":{"elapsed":1301,"status":"ok","timestamp":1620084727290,"user":{"displayName":"Aymé Arango","photoUrl":"","userId":"07842034733641806658"},"user_tz":240},"outputId":"dd3194d7-c083-4a2a-a146-679fe0a5ff65"},"source":["## ejecutar este código\n","\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.dummy import DummyClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB  # naive bayes\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC  # support vector machine classifier\n","\n","bc = load_breast_cancer()    # dataset cancer de mamas\n","X = bc.data\n","y = bc.target\n","\n","c0 = (\"Base Dummy\", DummyClassifier(strategy='stratified'))\n","c1 = (\"Decision Tree\", DecisionTreeClassifier(max_depth=5))\n","c2 = (\"Gaussian Naive Bayes\", GaussianNB())\n","c3 = (\"KNN\", KNeighborsClassifier(n_neighbors=10))\n","c4 = (\"Support Vector Machines\", SVC())\n","\n","classifiers = [c0, c1, c2, c3, c4]\n","\n","results = {}\n","for name, clf in classifiers:\n","    metrics = run_classifier(clf, X, y)   # hay que implementarla en el bloque anterior.\n","    results[name] = metrics\n","    print(\"----------------\")\n","    print(\"Resultados para clasificador: \", name) \n","    print(\"Precision promedio:\", np.array(metrics['precision']).mean())\n","    print(\"Recall promedio:\", np.array(metrics['recall']).mean())\n","    print(\"F1-score promedio:\", np.array(metrics['f1-score']).mean())\n","    print(\"----------------\\n\\n\")  "],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["----------------\n","Resultados para clasificador:  Base Dummy\n","Precision promedio: 0.6335652411005162\n","Recall promedio: 0.6192654862620001\n","F1-score promedio: 0.624805941676755\n","----------------\n","\n","\n","----------------\n","Resultados para clasificador:  Decision Tree\n","Precision promedio: 0.9462933521154281\n","Recall promedio: 0.9462303840468056\n","F1-score promedio: 0.945969299642483\n","----------------\n","\n","\n","----------------\n","Resultados para clasificador:  Gaussian Naive Bayes\n","Precision promedio: 0.9381569442658741\n","Recall promedio: 0.9687069269655314\n","F1-score promedio: 0.953037362099608\n","----------------\n","\n","\n","----------------\n","Resultados para clasificador:  KNN\n","Precision promedio: 0.9282181586955324\n","Recall promedio: 0.9628011662443874\n","F1-score promedio: 0.944935095281782\n","----------------\n","\n","\n","----------------\n","Resultados para clasificador:  Support Vector Machines\n","Precision promedio: 0.8871506661702706\n","Recall promedio: 0.9849252825620516\n","F1-score promedio: 0.9331337502957257\n","----------------\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"mcdnXXH6XADX"},"source":["## Pregunta 1.2\n","\n","Analizando los resultados obtenidos de cada clasificador, y basándose en las métricas calculadas. ¿Cuál es el mejor clasificador? ¿Qué métricas observó para tomar esa decisión y por qué? considerando el problema que aborda. Fundamente su respuesta."]},{"cell_type":"markdown","metadata":{"id":"w4y5d8pjXADX"},"source":["\n","***PAUTA 1.2***\n","\n","Es imposible determinar una medida que sea la mejor para todas las situaciones/problemas pero si es posible encontrar un balance entre estas. En general, **F1-score** considera una media armónica entre Recall y Precision por lo que utilizar esta medida para comparar sería útil para esta pregunta. También debemos considerar que en este caso particular podría interesarnos más el **Recall** para minimizar los falsos negativos (cuando se predice que una persona con cáncer no tiene cáncer).\n","\n","En este caso, no podríamos decir siempre cual es el mejor clasificador ya que está el factor aleatorio de cada clasificador que puede variar los resultados en cada ejecución (pero si podrían decir cual fue el mejor en la ejecución del código). \n"]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-28T00:01:32.541764Z","start_time":"2020-09-28T00:01:32.538758Z"},"id":"dcgTjBD7XADZ"},"source":["# Parte 2: Seleccionar hiperparámetros"]},{"cell_type":"markdown","metadata":{"id":"0p7LwuvEXADa"},"source":["Los hiperparámetros son parámetros que no se aprenden directamente dentro de los estimadores. En scikit-learn se pasan como argumentos al constructor de las clases, por ejemplo cuál kernel usar para Support Vector Classifier, o qué criterio para Decision Tree, etc. Es posible y recomendable buscar en el espacio de hiperparámetros la mejor alternativa.\n","\n","Tenga en cuenta que es común que un pequeño subconjunto de esos parámetros pueda tener un gran impacto en el rendimiento predictivo o de cálculo del modelo, mientras que otros pueden dejar sus valores predeterminados. Se recomienda leer la documentación de la clase de estimador para obtener una mejor comprensión de su comportamiento esperado."]},{"cell_type":"markdown","metadata":{"id":"-XnXy9a7XADa"},"source":["## GridSearchCV\n","\n","Una alternativa para seleccionar hiperparámetros es GridSearchCV, la cual considera exhaustivamente todas las combinaciones de parámetros. GridSearchCV recibe un *estimador*, recibe *param_grid* (un diccionario o una lista de diccionarios con los nombres de los parametros a probar como keys y una lista de los valores a probar), *scoring* una o varias funciones de puntuación (score) para evaluar cada combinación de parametros (opciones válidas: https://scikit-learn.org/stable/modules/model_evaluation.html) y *cv* una extrategia para hacer validación cruzada.\n","\n","El siguiente código muestra cómo seleccionar el número de vecinos y qué pesos otorgar a los vecinos en un clasificador KNN. \n"," \n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:38.025125Z","start_time":"2020-09-28T01:11:37.749394Z"},"id":"mlzgox92XADb","executionInfo":{"elapsed":11499,"status":"aborted","timestamp":1620084533029,"user":{"displayName":"Aymé Arango","photoUrl":"","userId":"07842034733641806658"},"user_tz":240},"outputId":"7c497a07-69e0-43f4-d52c-89d5d70c9857"},"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n","\n","#Configure tuned_parameters\n","tuned_parameters = {'n_neighbors': [1, 3, 5, 10], \n","                    'weights': ['uniform','distance']}\n","\n","#set scoring metric\n","score = 'precision' \n","\n","#Construir el clf con GridSearch\n","clf = GridSearchCV(KNeighborsClassifier(), \n","                   param_grid=tuned_parameters, \n","                   cv=5,\n","                   scoring=score)\n","\n","#Entrenar clf\n","clf.fit(X_train, y_train)\n","\n","print(\"Mejor combinación de parámetros:\")\n","print(clf.best_params_)\n"," \n","y_true, y_pred = y_test, clf.predict(X_test)\n","\n","print(classification_report(y_true, y_pred))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mejor combinación de parámetros:\n","{'n_neighbors': 5, 'weights': 'uniform'}\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.81      0.89        58\n","           1       0.91      0.99      0.95       113\n","\n","    accuracy                           0.93       171\n","   macro avg       0.94      0.90      0.92       171\n","weighted avg       0.93      0.93      0.93       171\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"BX8g3y2zXADd"},"source":["## Pregunta 2.1\n","\n","*  a) Realice este mismo proceso para un clasificador DecisionTree y los parametros criterion=['gini','entropy'], max_depth=[2,7,10] y tomando como scoring metric 'f1'. Use cv=4\n","*  b) ¿Qué puede decir de los resultados, con cuáles parámetros los obtuvo (revise que su respuesta concuerde con lo que imprime)? ¿Cuál considera que es la principal ventaja de aplicar GridSearchCV? ¿Considera que es necesario seguir explorando los parámetros?"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:38.300858Z","start_time":"2020-09-28T01:11:38.027133Z"},"id":"vSmxont4XADd","executionInfo":{"elapsed":11495,"status":"aborted","timestamp":1620084533032,"user":{"displayName":"Aymé Arango","photoUrl":"","userId":"07842034733641806658"},"user_tz":240},"outputId":"571072e4-3699-4e65-a183-a70238d5739a"},"source":["## RESPUESTA A PREGUNTA 2.1 a)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n","\n","## COMPLETE ACÁ\n","\n","########## INICIO PAUTA ############\n","\n","#Configure tuned_parameters\n","tuned_parameters = {'criterion': ['gini','entropy'], 'max_depth': [2, 7, 10]} \n","\n","#set scoring metric\n","score = 'f1'\n","\n","#Construir el clf con GridSearch y luego entrenar (guiarse con la sección anterior pero ahora con decision tree)\n","clf = GridSearchCV(DecisionTreeClassifier(), \n","                   param_grid=tuned_parameters, \n","                   cv=4,\n","                   scoring=score)\n","\n","clf.fit(X_train, y_train)\n","\n","########## FIN PAUTA ############\n","\n","print(\"Mejor combinación de parámetros:\")\n","print(clf.best_params_)\n"," \n","y_true, y_pred = y_test, clf.predict(X_test)\n","print(classification_report(y_true, y_pred))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mejor combinación de parámetros:\n","{'criterion': 'entropy', 'max_depth': 7}\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.92      0.91        61\n","           1       0.95      0.95      0.95       110\n","\n","    accuracy                           0.94       171\n","   macro avg       0.93      0.93      0.93       171\n","weighted avg       0.94      0.94      0.94       171\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"kXKBdWKoXADp"},"source":["### Respuesta 2.1 continuación b)\n","\n","Los resultados muestran que *entropy* es el mejor criterio de seleccion (Por defecto el modelo usa *gini* y en algunas ejecuciones da mejor con gini). Con max_depth=7 se obtienen los mejores resultados (a veces se obtienen con max_depth=10 por lo que sería conveniente explorar max_depth con valores más grandes).\n","\n","La principal ventaja de este análisis podría ser que nos permite probar un rango amplio de hiperparámetros lo cual nos permite encontrar los más adecuados para nuestro modelo.\n","\n","Si bien para este caso se puede dejar max_depth=None y que el modelo use la profundidad necesaria, pueden haber casos donde el dataset sea muy grande y sea necesario establecer max_depth a un número razonable para reducir el costo computacional."]},{"cell_type":"markdown","metadata":{"id":"Rf4BSIjTXADq"},"source":["# Parte 3: Trabajar con clases desbalanceadas"]},{"cell_type":"markdown","metadata":{"id":"W3fb8kQ7XADq"},"source":["Para mejorar el rendimiento de un clasificador sobre clases desbalanceadas existen varias técnicas. En esta parte, veremos cómo tratar con este problema usando (sub/over) sampling de las clases.\n","\n","(*Nota: Para ejecutar el siguiente bloque es necesaria la librería `pandas` que viene incluida en Anaconda.*)"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:38.465037Z","start_time":"2020-09-28T01:11:38.302866Z"},"id":"lcXqhaBzXADr","executionInfo":{"elapsed":11491,"status":"aborted","timestamp":1620084533035,"user":{"displayName":"Aymé Arango","photoUrl":"","userId":"07842034733641806658"},"user_tz":240},"outputId":"638e8cf4-c95b-4963-ae9a-e3f7498e6309"},"source":["import pandas as pd\n","\n","# Cargamos dataset desbalanceado\n","unbalanced_path = 'https://users.dcc.uchile.cl/~hsarmien/mineria/datasets/unbalanced.csv'\n","data = pd.read_csv(unbalanced_path)  # abrimos el archivo csv y lo cargamos en data\n","data.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>V11</th>\n","      <th>V12</th>\n","      <th>...</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>V29</th>\n","      <th>V30</th>\n","      <th>V31</th>\n","      <th>V32</th>\n","      <th>V33</th>\n","      <th>V34</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.99539</td>\n","      <td>-0.05889</td>\n","      <td>0.85243</td>\n","      <td>0.02306</td>\n","      <td>0.83398</td>\n","      <td>-0.37708</td>\n","      <td>1.00000</td>\n","      <td>0.03760</td>\n","      <td>0.85243</td>\n","      <td>-0.17755</td>\n","      <td>...</td>\n","      <td>-0.51171</td>\n","      <td>0.41078</td>\n","      <td>-0.46168</td>\n","      <td>0.21266</td>\n","      <td>-0.34090</td>\n","      <td>0.42267</td>\n","      <td>-0.54487</td>\n","      <td>0.18641</td>\n","      <td>-0.45300</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.00000</td>\n","      <td>-0.18829</td>\n","      <td>0.93035</td>\n","      <td>-0.36156</td>\n","      <td>-0.10868</td>\n","      <td>-0.93597</td>\n","      <td>1.00000</td>\n","      <td>-0.04549</td>\n","      <td>0.50874</td>\n","      <td>-0.67743</td>\n","      <td>...</td>\n","      <td>-0.26569</td>\n","      <td>-0.20468</td>\n","      <td>-0.18401</td>\n","      <td>-0.19040</td>\n","      <td>-0.11593</td>\n","      <td>-0.16626</td>\n","      <td>-0.06288</td>\n","      <td>-0.13738</td>\n","      <td>-0.02447</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.00000</td>\n","      <td>-0.03365</td>\n","      <td>1.00000</td>\n","      <td>0.00485</td>\n","      <td>1.00000</td>\n","      <td>-0.12062</td>\n","      <td>0.88965</td>\n","      <td>0.01198</td>\n","      <td>0.73082</td>\n","      <td>0.05346</td>\n","      <td>...</td>\n","      <td>-0.40220</td>\n","      <td>0.58984</td>\n","      <td>-0.22145</td>\n","      <td>0.43100</td>\n","      <td>-0.17365</td>\n","      <td>0.60436</td>\n","      <td>-0.24180</td>\n","      <td>0.56045</td>\n","      <td>-0.38238</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.00000</td>\n","      <td>-0.45161</td>\n","      <td>1.00000</td>\n","      <td>1.00000</td>\n","      <td>0.71216</td>\n","      <td>-1.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>...</td>\n","      <td>0.90695</td>\n","      <td>0.51613</td>\n","      <td>1.00000</td>\n","      <td>1.00000</td>\n","      <td>-0.20099</td>\n","      <td>0.25682</td>\n","      <td>1.00000</td>\n","      <td>-0.32382</td>\n","      <td>1.00000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.00000</td>\n","      <td>-0.02401</td>\n","      <td>0.94140</td>\n","      <td>0.06531</td>\n","      <td>0.92106</td>\n","      <td>-0.23255</td>\n","      <td>0.77152</td>\n","      <td>-0.16399</td>\n","      <td>0.52798</td>\n","      <td>-0.20275</td>\n","      <td>...</td>\n","      <td>-0.65158</td>\n","      <td>0.13290</td>\n","      <td>-0.53206</td>\n","      <td>0.02431</td>\n","      <td>-0.62197</td>\n","      <td>-0.05707</td>\n","      <td>-0.59573</td>\n","      <td>-0.04608</td>\n","      <td>-0.65697</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 33 columns</p>\n","</div>"],"text/plain":["        V3       V4       V5       V6       V7       V8       V9      V10  \\\n","0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000  0.03760   \n","1  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000 -0.04549   \n","2  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965  0.01198   \n","3  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000  0.00000   \n","4  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152 -0.16399   \n","\n","       V11      V12  ...      V26      V27      V28      V29      V30  \\\n","0  0.85243 -0.17755  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090   \n","1  0.50874 -0.67743  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593   \n","2  0.73082  0.05346  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365   \n","3  0.00000  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099   \n","4  0.52798 -0.20275  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197   \n","\n","       V31      V32      V33      V34  Class  \n","0  0.42267 -0.54487  0.18641 -0.45300      0  \n","1 -0.16626 -0.06288 -0.13738 -0.02447      1  \n","2  0.60436 -0.24180  0.56045 -0.38238      0  \n","3  0.25682  1.00000 -0.32382  1.00000      1  \n","4 -0.05707 -0.59573 -0.04608 -0.65697      0  \n","\n","[5 rows x 33 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-09-28T00:36:22.116129Z","start_time":"2020-09-28T00:36:22.111116Z"},"id":"QFNMUPd-XADu"},"source":["Note el desbalance de las clases ejecutando el siguiente código:"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:38.476062Z","start_time":"2020-09-28T01:11:38.467038Z"},"id":"lXrcsboyXADu","executionInfo":{"elapsed":11488,"status":"aborted","timestamp":1620084533038,"user":{"displayName":"Aymé Arango","photoUrl":"","userId":"07842034733641806658"},"user_tz":240},"outputId":"1ae353ea-5f07-4e11-8f31-9b75b5f3000d"},"source":["print(\"Distribucion de clases original\")\n","data['Class'].value_counts()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Distribucion de clases original\n"]},{"data":{"text/plain":["0    225\n","1    126\n","Name: Class, dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"nlMr6-9GXADx"},"source":["Antes de hacer algo para tratar el desbalance entre las clases primero debemos dividir en train-test."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:38.496117Z","start_time":"2020-09-28T01:11:38.478068Z"},"id":"Qr7JzTG-XADy","executionInfo":{"elapsed":11484,"status":"aborted","timestamp":1620084533040,"user":{"displayName":"Aymé Arango","photoUrl":"","userId":"07842034733641806658"},"user_tz":240},"outputId":"4931efba-901f-4536-b60e-a9091008481d"},"source":["data_train, data_test, ytrain, ytest = train_test_split(data, data['Class'], test_size=0.3, stratify=data['Class'])\n","# proporción de clases en el train después de dividir en train-test\n","ytrain.value_counts()"],"execution_count":null,"outputs":[{"data":{"text/plain":["0    157\n","1     88\n","Name: Class, dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"q_X5CY14XAD3"},"source":["Ahora, usando el dataset anterior, aplicaremos **oversampling** y **subsampling** al train para que queden balanceados. Ejecute el siguiente código y note ahora que las clases están balanceadas. "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:38.534218Z","start_time":"2020-09-28T01:11:38.510154Z"},"id":"WpXH_EZkXAD4","executionInfo":{"elapsed":11480,"status":"aborted","timestamp":1620084533047,"user":{"displayName":"Aymé Arango","photoUrl":"","userId":"07842034733641806658"},"user_tz":240},"outputId":"355672b7-999a-4f9b-800a-bf2f57ca9217"},"source":["import numpy as np\n","\n","print(\"Distribución de clases usando (over/sub) sampling\")\n","print()\n","\n","data_train = data_train.reset_index(drop=True)\n","\n","# oversampling sobre la clase 1\n","idx = np.random.choice(data_train[data_train['Class'] == 1].index, size=69)\n","data_oversampled = pd.concat([data_train, data_train.iloc[idx]])\n","print(\"Data oversampled on class '1'\")\n","print(data_oversampled['Class'].value_counts())\n","print()\n","\n","\n","# subsampling sobre la clase 0\n","idx = np.random.choice(data_train.loc[data_train.Class == 0].index, size=69, replace=False)\n","data_subsampled = data_train.drop(data_train.iloc[idx].index)\n","print(\"Data subsampled on class '0'\")\n","print(data_subsampled['Class'].value_counts())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Distribución de clases usando (over/sub) sampling\n","\n","Data oversampled on class '1'\n","0    157\n","1    157\n","Name: Class, dtype: int64\n","\n","Data subsampled on class '0'\n","0    88\n","1    88\n","Name: Class, dtype: int64\n"]}]},{"cell_type":"markdown","metadata":{"id":"urh4G7FhXAD6"},"source":["**Nota:** *Librerías como `imblearn` son muy útiles para balancear los datos.*"]},{"cell_type":"markdown","metadata":{"id":"lNRoMB4bXAD6"},"source":["## Pregunta 3. 1\n","\n","¿Por qué aplicar subsampling/oversampling de las clases sobre el conjunto de entrenamiento en lugar de aplicarlo sobre el dataset completo?\n","\n","**Respuesta:**"]},{"cell_type":"markdown","metadata":{"id":"Vg8oRomlXAD6"},"source":["### Respuesta 3.1 \n","########### inicio de pauta ############\n","\n","Para mantener la distribución natural de los datos que serán utilizados para evaluar el desempeño real del modelo. Si estos también fueran equilibrados, los resultados no indicarían cómo se desempeñaría el modelo con los datos reales. \n","\n","\n","############ fin de pauta ############"]},{"cell_type":"code","metadata":{"id":"Mich8PsMQ3uw"},"source":["## ejecutar este código para preparar los datos\n","from sklearn.metrics import classification_report\n","\n","# Preparando los data frames para ser compatibles con sklearn\n","\n","# datos test (mismo para todos los conjuntos de entrenamiento)\n","X_test = data_test[data_train.columns[:-1]] # todo hasta la penultima columna\n","y_test = data_test[data_train.columns[-1]]  # la última columna\n","\n","# datos entrenamiento \"originales\"\n","X_orig = data_train[data_train.columns[:-1]] \n","y_orig = data_train[data_train.columns[-1]] \n","\n","# datos entrenamiento \"oversampleados\" \n","X_over = data_oversampled[data_train.columns[:-1]]\n","y_over = data_oversampled[data_train.columns[-1]]\n","\n","# datos entrenamiento \"subsampleados\"\n","X_subs = data_subsampled[data_train.columns[:-1]]\n","y_subs = data_subsampled[data_train.columns[-1]]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AWA7_lHxXAD7"},"source":["## Pregunta 3.2\n","\n","Complete el código necesario para entrenar un clasificador (DecisionTreeClassifier) en cada uno de los tres casos (**original**, con **oversampling** y con **subsampling**) y luego compare los resultados sobre el conjunto de test (el mismo para los tres casos) obtenido con train_test_split sobre los datos originales. Muestre Precision, Recall y F1-score.\n","\n","Emplee como datos de entrada lo del bloque anterior. "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-28T01:11:38.601396Z","start_time":"2020-09-28T01:11:38.553269Z"},"id":"AXu3Hx77XAD9","executionInfo":{"elapsed":11477,"status":"aborted","timestamp":1620084533054,"user":{"displayName":"Aymé Arango","photoUrl":"","userId":"07842034733641806658"},"user_tz":240},"outputId":"4fcfd653-c1c6-46b4-f315-0d98f6be96d1"},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","\n","## Pasos:\n","##  - instanciar el clasificador con DecisionTreeClassifier()\n","##  - entrenar con fit()\n","##  - hacer las predicciones\n","##  - mostrar precision, recall y f1-score con classification report.\n","\n","print(\"ORIGINAL::::::::::\")\n","clf_orig = DecisionTreeClassifier()\n","clf_orig.fit(X_orig, y_orig)\n","pred_orig = clf_orig.predict(X_test)\n","print(classification_report(y_test, pred_orig))\n","\n","###########PAUTA#############\n","\n","print(\"OVERSAMPLING::::::::::\")\n","clf_over = DecisionTreeClassifier()\n","clf_over.fit(X_over, y_over)\n","pred_over = clf_over.predict(X_test)\n","print(classification_report(y_test, pred_over))\n","\n","print(\"SUBSAMPLING::::::::::\")\n","clf_subs = DecisionTreeClassifier()\n","clf_subs.fit(X_subs, y_subs)\n","pred_subs = clf_subs.predict(X_test)\n","print(classification_report(y_test, pred_subs))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["ORIGINAL::::::::::\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.93      0.93        68\n","           1       0.87      0.89      0.88        38\n","\n","    accuracy                           0.92       106\n","   macro avg       0.91      0.91      0.91       106\n","weighted avg       0.92      0.92      0.92       106\n","\n","OVERSAMPLING::::::::::\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.91      0.91        68\n","           1       0.84      0.82      0.83        38\n","\n","    accuracy                           0.88       106\n","   macro avg       0.87      0.86      0.87       106\n","weighted avg       0.88      0.88      0.88       106\n","\n","SUBSAMPLING::::::::::\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.82      0.88        68\n","           1       0.74      0.92      0.82        38\n","\n","    accuracy                           0.86       106\n","   macro avg       0.85      0.87      0.85       106\n","weighted avg       0.88      0.86      0.86       106\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"5XkE5zruXAD-"},"source":["## Pregunta 3.3\n","\n","- Observe los resultados obtenidos por clase con cada conjunto de entrenamiento, ¿se puede observar alguna diferencia importante? \n","- Indique una desventaja de usar oversampling y una desventaja de usar subsampling en clasificación."]},{"cell_type":"markdown","metadata":{"id":"CT_8XDc6XAD-"},"source":["### Respuesta a pregunta 3.2\n","########### inicio pauta ############\n","\n","En promedio los resultados son similares para todas las estrategias, sin embargo, se puede ver la diferencia por clase. La estrategia oversampling presenta mejores resultados para la clase minoritaria (aunque puede que no siempre de mejor la misma estrategia). \n","\n","Recuerde que F1-score es la métrica más conveniente para elegir la mejor estrategia.\n","\n","El oversampling altera la proporción de los datos minoritarios, lo cual puede generar overfitting respecto a estos ya que se tienden a repetir muchos de los datos minoritarios. \n","\n","La desventaja del subsampling es que perdemos información y puede crear un sesgo.\n","\n","########### fin pauta ############"]}]}